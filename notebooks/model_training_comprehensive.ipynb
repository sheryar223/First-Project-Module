{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48211657",
   "metadata": {},
   "source": [
    "Calorie Burn Prediction - Comprehensive Model Training\n",
    "Author: Sheryar & Shamoon Waheed\n",
    "Purpose: Train and compare multiple ML models for calorie prediction\n",
    "\n",
    "Notebook Overview:\n",
    "Import libraries and setup\n",
    "Load and explore data\n",
    "Feature engineering (MET values)\n",
    "Train multiple models\n",
    "Compare performance\n",
    "Generate visualizations\n",
    "Save best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8789826d",
   "metadata": {},
   "source": [
    "[CODE] - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e360f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d2f09",
   "metadata": {},
   "source": [
    "Setup Paths and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d1fa2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CALORIE BURN PREDICTION - MODEL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Setup paths (relative to notebook location)\n",
    "DATA_PATH = Path('../data/enhanced_calories.csv')\n",
    "MODEL_DIR = Path('../models')\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# MET values for workouts\n",
    "MET_MAPPING = {\n",
    "    'Pushups': 3.8,\n",
    "    'Pullups': 4.0,\n",
    "    'Cycling': 6.8,\n",
    "    'Hill_Up': 9.0,\n",
    "    'Hill_Down': 5.0,\n",
    "    'Hill_Straight': 7.0,\n",
    "    'Jumping_Jacks': 8.0,\n",
    "    'Burpees': 8.0,\n",
    "    'Running_in_Place': 7.0,\n",
    "    'Walking': 3.5,\n",
    "    'Yoga': 2.5\n",
    "}\n",
    "\n",
    "print(f\"Paths configured\")\n",
    "print(f\"Data: {DATA_PATH}\")\n",
    "print(f\"Models: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329cb326",
   "metadata": {},
   "source": [
    "Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c06150",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"✓ Loaded {len(df)} rows\")\n",
    "\n",
    "# Quick exploration\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(df.head())\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc144d1d",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b68e2d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['MET'] = df['Workout_Type'].map(MET_MAPPING)\n",
    "print(f\"✓ MET values added\")\n",
    "print(f\"\\nMET Distribution:\")\n",
    "print(df.groupby('Workout_Type')['MET'].first().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1423cea1",
   "metadata": {},
   "source": [
    "Prepare Features and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43558dcb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nPreparing features...\")\n",
    "feature_cols = ['Gender', 'Age', 'Height', 'Weight', 'Duration', \n",
    "                'Heart_Rate', 'Body_Temp', 'MET']\n",
    "X = df[feature_cols]\n",
    "y = df['Calories']\n",
    "print(f\"✓ Features shape: {X.shape}\")\n",
    "\n",
    "# Create preprocessor\n",
    "num_cols = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'MET']\n",
    "cat_cols = ['Gender']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"✓ Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Preprocess\n",
    "print(\"\\nPreprocessing data...\")\n",
    "X_train_pre = preprocessor.fit_transform(X_train)\n",
    "X_test_pre = preprocessor.transform(X_test)\n",
    "print(f\"Preprocessed shape: {X_train_pre.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c65aad",
   "metadata": {},
   "source": [
    "Train Multiple Models\n",
    "We'll train 3 different models and compare:\n",
    "\n",
    "Linear Regression (baseline)\n",
    "Random Forest (ensemble)\n",
    "XGBoost (gradient boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaca4ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nTraining Multiple Models...\")\n",
    "models_performance = {}\n",
    "\n",
    "# Model 1: Linear Regression\n",
    "print(\"\\n1. Linear Regression (Baseline)...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_pre, y_train)\n",
    "y_pred_lr_train = lr_model.predict(X_train_pre)\n",
    "y_pred_lr_test = lr_model.predict(X_test_pre)\n",
    "\n",
    "models_performance['Linear Regression'] = {\n",
    "    'model': lr_model,\n",
    "    'r2_train': r2_score(y_train, y_pred_lr_train),\n",
    "    'r2_test': r2_score(y_test, y_pred_lr_test),\n",
    "    'mae': mean_absolute_error(y_test, y_pred_lr_test),\n",
    "    'rmse': np.sqrt(mean_squared_error(y_test, y_pred_lr_test)),\n",
    "    'predictions': y_pred_lr_test\n",
    "}\n",
    "print(f\"   R² Test: {models_performance['Linear Regression']['r2_test']:.4f}\")\n",
    "\n",
    "# Model 2: Random Forest\n",
    "print(\"\\n2. Random Forest...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=150,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train_pre, y_train)\n",
    "y_pred_rf_train = rf_model.predict(X_train_pre)\n",
    "y_pred_rf_test = rf_model.predict(X_test_pre)\n",
    "\n",
    "models_performance['Random Forest'] = {\n",
    "    'model': rf_model,\n",
    "    'r2_train': r2_score(y_train, y_pred_rf_train),\n",
    "    'r2_test': r2_score(y_test, y_pred_rf_test),\n",
    "    'mae': mean_absolute_error(y_test, y_pred_rf_test),\n",
    "    'rmse': np.sqrt(mean_squared_error(y_test, y_pred_rf_test)),\n",
    "    'predictions': y_pred_rf_test\n",
    "}\n",
    "print(f\"   R² Test: {models_performance['Random Forest']['r2_test']:.4f}\")\n",
    "\n",
    "# Model 3: XGBoost\n",
    "print(\"\\n3. XGBoost...\")\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=150,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train_pre, y_train)\n",
    "y_pred_xgb_train = xgb_model.predict(X_train_pre)\n",
    "y_pred_xgb_test = xgb_model.predict(X_test_pre)\n",
    "\n",
    "models_performance['XGBoost'] = {\n",
    "    'model': xgb_model,\n",
    "    'r2_train': r2_score(y_train, y_pred_xgb_train),\n",
    "    'r2_test': r2_score(y_test, y_pred_xgb_test),\n",
    "    'mae': mean_absolute_error(y_test, y_pred_xgb_test),\n",
    "    'rmse': np.sqrt(mean_squared_error(y_test, y_pred_xgb_test)),\n",
    "    'predictions': y_pred_xgb_test\n",
    "}\n",
    "print(f\"   R² Test: {models_performance['XGBoost']['r2_test']:.4f}\")\n",
    "\n",
    "print(\"\\nAll models trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45faa73f",
   "metadata": {},
   "source": [
    "Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd1591",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nModel Comparison:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<20} {'R² Train':<12} {'R² Test':<12} {'MAE':<10} {'RMSE':<10}\")\n",
    "print(\"=\"*70)\n",
    "for name, perf in models_performance.items():\n",
    "    print(f\"{name:<20} {perf['r2_train']:<12.4f} {perf['r2_test']:<12.4f} {perf['mae']:<10.2f} {perf['rmse']:<10.2f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select best model\n",
    "best_model_name = max(models_performance.keys(), key=lambda k: models_performance[k]['r2_test'])\n",
    "best_model_perf = models_performance[best_model_name]\n",
    "model = best_model_perf['model']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"   R² Test: {best_model_perf['r2_test']:.4f}\")\n",
    "print(f\"   MAE: {best_model_perf['mae']:.2f} kcal\")\n",
    "\n",
    "r2_train = best_model_perf['r2_train']\n",
    "r2_test = best_model_perf['r2_test']\n",
    "mae = best_model_perf['mae']\n",
    "rmse = best_model_perf['rmse']\n",
    "y_pred_test = best_model_perf['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106539cf",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7b6f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nCreating comprehensive analysis plots...\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Model Comparison Bar Chart\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "model_names = list(models_performance.keys())\n",
    "r2_scores = [models_performance[m]['r2_test'] for m in model_names]\n",
    "colors = ['#FF6B6B' if m != best_model_name else '#51CF66' for m in model_names]\n",
    "bars = ax1.bar(model_names, r2_scores, color=colors)\n",
    "ax1.set_ylabel('R² Score')\n",
    "ax1.set_title('Model Comparison (R² Test Score)')\n",
    "ax1.set_ylim([min(r2_scores) - 0.01, 1.0])\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{r2_scores[i]:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ... (continue with all other plots from Code 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'comprehensive_analysis.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Comprehensive analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adab013",
   "metadata": {},
   "source": [
    "Save Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d5707",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nSaving model artifacts...\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, MODEL_DIR / 'calories_model.pkl')\n",
    "print(\"Model saved\")\n",
    "\n",
    "# Save preprocessor\n",
    "joblib.dump(preprocessor, MODEL_DIR / 'preprocessor.pkl')\n",
    "print(\"Preprocessor saved\")\n",
    "\n",
    "# Save MET mapping\n",
    "joblib.dump(MET_MAPPING, MODEL_DIR / 'met_mapping.pkl')\n",
    "print(\"MET mapping saved\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'best_model': best_model_name,\n",
    "    'r2_test': float(r2_test),\n",
    "    'mae_test': float(mae),\n",
    "    'rmse_test': float(rmse)\n",
    "}\n",
    "with open(MODEL_DIR / 'model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"Metadata saved\")\n",
    "\n",
    "print(\"\\nTRAINING COMPLETE!\")\n",
    "print(f\"Model Accuracy: R²={r2_test:.4f}, Error=±{mae:.1f} kcal\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
